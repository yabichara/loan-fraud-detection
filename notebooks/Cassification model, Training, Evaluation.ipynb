{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2b1e12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas already installed and up to date (version 1.3.4).\n",
      "numpy already installed and up to date (version 1.20.3).\n",
      "matplotlib already installed and up to date (version 3.4.3).\n",
      "seaborn already installed and up to date (version 0.11.2).\n",
      "scikit-learn already installed and up to date (version 1.6.1).\n",
      "lightgbm already installed and up to date (version 4.6.0).\n",
      "imblearn already installed and up to date (version 0.0).\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "def install_requirements(file='../requirements.txt'):\n",
    "    try:\n",
    "        with open(file) as f:\n",
    "            packages = [line.strip() for line in f if line.strip() and not line.startswith('#')]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{file} not found.\")\n",
    "        return\n",
    "\n",
    "    for package in packages:\n",
    "        # Extract package name without version specifier for import\n",
    "        pkg_name = package.split('==')[0].split('>=')[0].split('<=')[0]\n",
    "\n",
    "        try:\n",
    "            # Check if the package is installed\n",
    "            dist = pkg_resources.get_distribution(pkg_name)\n",
    "            installed_version = dist.version\n",
    "\n",
    "            # Check if the installed version satisfies the requirement\n",
    "            requirement = pkg_resources.Requirement.parse(package)\n",
    "            if installed_version not in requirement:\n",
    "                print(f\"Upgrading {package} (installed version: {installed_version})...\")\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package])\n",
    "            else:\n",
    "                print(f\"{package} already installed and up to date (version {installed_version}).\")\n",
    "\n",
    "        except pkg_resources.DistributionNotFound:\n",
    "            print(f\"Installing {package}...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install_requirements()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18d44820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c54c7",
   "metadata": {},
   "source": [
    "# Processed Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d87d74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Processed/loan_transactions_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad6648",
   "metadata": {},
   "source": [
    "# Data preprocessing for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b85d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define target variables\n",
    "y_fraud = df['fraud_flag']\n",
    "y_loan_status = df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64391017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the feature set X by dropping irrelevant columns\n",
    "X = df.drop(columns=['fraud_flag', 'loan_status', 'fraud_type', 'application_id', 'customer_id', 'application_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ec78407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumerical features:\u001b[0m ['application_year', 'application_month', 'application_day_of_week', 'applicant_age', 'number_of_dependents', 'monthly_income', 'cibil_score', 'loan_amount_requested', 'loan_tenure_months', 'interest_rate_offered', 'loan_amount_to_income_ratio', 'existing_emis_monthly', 'existing_emi_to_income_ratio', 'debt_to_income_ratio', 'transaction_count', 'total_transaction_amount', 'avg_transaction_amount', 'max_transaction_amount', 'fraud_count', 'fraud_rate', 'international_txn_rate', 'unique_devices_used', 'transaction_count_pre', 'total_amount_pre', 'avg_amount_pre', 'fraud_count_pre', 'fraud_rate_pre']\n",
      "----------------------------------------------------------------------\n",
      "\u001b[1mCategorical features:\u001b[0m ['gender', 'residential_address', 'property_ownership_status', 'employment_status', 'loan_type', 'purpose_of_loan']\n"
     ]
    }
   ],
   "source": [
    "# 3. Identify numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"\\033[1mNumerical features:\\033[0m\", numerical_features)\n",
    "print('-'*70)\n",
    "print(\"\\033[1mCategorical features:\\033[0m\", categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b062f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough' # Keep other columns that are not transformed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd2f9a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of original features X: (50000, 33)\n",
      "Shape of processed features X_processed: (50000, 18365)\n"
     ]
    }
   ],
   "source": [
    "# 5. Fit and transform the feature set X\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "print(\"\\nShape of original features X:\", X.shape)\n",
    "print(\"Shape of processed features X_processed:\", X_processed.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
